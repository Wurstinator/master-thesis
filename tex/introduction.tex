\section*{Introduction}

Finite automata are a long established computation model that dates back to sources such as \cite{McCulloch1990} and \cite{RabinScott1959}. A known problem for finite automata is state space reduction, referring to the search of a language-equivalent automaton which uses fewer states than the original object. For deterministic finite automata (DFA), not just reduction but minimization was solved in \cite{Hopcroft1971}. Regarding nondeterministic finite automata (NFA), \cite{JianRavikumar1991} proved the PSPACE-completeness of the minimization problem, which is why reduction algorithms such as \cite{ChamparnaudCoulon2004} and \cite{BonchiPous2013} are a popular alternative.

In his prominent work \cite{Buchi1966}, B\"uchi introduced the model of B\"uchi automata (BA) as an extension of finite automata to read words of one-sided infinite length. As these $\omega$-automata tend to have higher levels of complexity in comparison to standard finite automata, the potential gain of state space reduction is even greater. Similar to NFAs, exact minimization for deterministic B\"uchi automata was shown to be NP-complete in \cite{Schewe2010} and spawned heuristic approaches such as \cite{Schewe2010}, \cite{MayrClemente2012}, or \cite{EtessamiWilkeSchuller2001}. 

As \cite{Thomas1991} displays, deterministic B\"uchi automata are a strictly weaker model than nondeterministic Büchi automata. It is therefore interesting to consider different models of $\omega$-automata in which determinism is possible while maintaining enough power to describe all $\omega$-regular languages. Parity automata (PA) are one such model, a mixture of B\"uchi automata and Moore automata (\cite{Moore56}), that use a parity function, assigning states to output numbers, rather than the usual acceptance set. A run of a parity automaton is accepting if in the set of numbers that are output infinitely often has an even number as its minimum.
\cite{Mostowski1991}, \cite{Thomas1997} showed that deterministic parity automata are in fact sufficient to recognize all $\omega$-regular languages. As for DBAs, the exact minimization problem for DPAs is NP-complete (\cite{Schewe2010}).
\vspace{5pt}

In this paper, we research heuristic state space reduction techniques for DPAs. As a first step, a general framework is introduced. These \emph{merger functions} are a generalization of quotient automata which are e.g. used in the minimization of DFAs. The state set of an automaton is partitioned into multiple merge sets, each of which is mapped by the merger function to a set of candidate sets. A \emph{representative merge} then chooses a representative candidate and removes all other states from the particular merge set, redirecting all transitions to the representative. As an alternative to the representative merge, we also describe an alternative approach called a \emph{Schewe merge} based on ideas in \cite{Schewe2010}.

The most basic merge simply adapts the algorithm from \cite{Hopcroft1971}. Every parity automaton can be interpreted as a Moore automaton which can then be minimized using said algorithm. In this context, we call the equivalence relation which considers two states to be equivalent if they are merged by this algorithm the \emph{Moore equivalence}. That relation is used or modified at several later points of the thesis.

A simple merger function we introduce is that of the \emph{skip merger} which takes an equivalence relation that implies language equivalence on the states as a parameter and from that builds a merger function. The idea of using one given equivalence relation on the states and refining it is used several times in the thesis. This merge decides on one particular strongly connected component (SCC) of the automaton and removes all states of an equivalence class that do not lie in this SCC, essentially \enquote{skipping} all other SCCs.

We adapt the works of \cite{FritzWilke06}, who worked on alternating Büchi automata, to our case of deterministic parity automata and find that there are enough differences to warrant a separate analysis. The \emph{delayed simulation merger} considers two states to be equal, if on every run from those states on a shared word, if one run visits a priority at some position, the other run must visit a priority at most as high at some point in the future. It then holds that both runs will see the same smallest priority infinitely often and therefore either both accept or both reject. It suffices to choose one representative of each such equivalence class that has minimal priority and build the quotient automaton with those representatives.

The \emph{iterated Moore} merge uses the idea that on $\omega$-automata, states which are only visited finitely often are irrelevant to the acceptance of a state. In particular, trivial SCCs, i.e. states with no path back to itself, can have their priority freely changed without effecting the language of the automaton. The idea of this merger therefore is to loosen the constraints on those states and then build the usual Moore equivalence.

We bring up merging via \emph{path refinement}, which uses an existing equivalence class of some congruence relation and refines it to a point where states can safely be merged. This refinement occurs so that two states from the class are equivalent if on each path from that state back to the class, both states visit the same minimal priority. 

Another merger function is called \emph{threshold Moore}, which again refines an existing relation. Two states are considered to be equivalent under the refinement if a relaxation of Moore equivalence, that considers all priorities greater than some $k$ to be equal, matches them. In this case we require the two states to have equal priority and choose the $k$ to be that exact value.

A similar but slightly different approach is the \emph{LSF} merger function. It removes the need for two states to have equal priority and instead takes the value $k$ as a parameter. On the other side it adds a requirement similar to that of the skip merger, in that the candidates of the merge are those that all lie in one single SCC if we modify the automaton to only contain those states of priority at least $k$.
\vspace{5pt}

The thesis is structured as follows: In the first chapter, we define basics notations and conventions and present some data of our empirical testing environment used to collect practical data of each approach.
In the second chapter, we establish some theoretical ground work that will be used by the rest of the thesis.
After that, we present the algorithms for state space reduction, split into one chapter for each such procedure. Each such chapter is made up of at least three sections. The first section describes the idea and definition of the algorithm and proofs well behaving properties. The second section covers how to actually compute the reduction and provides a short run time analysis. The third section shows practical data to analyze \enquote{real world} usefulness. Potential other sections contain variants or extensions of the original procedure as well as potential open questions. 
At the very end, the appendix includes small examples to show how the individual merger functions are computed and work.




