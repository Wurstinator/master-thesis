

\title{State Space Reduction For Parity Automata}
\author{Christof Löding \and Andreas Tollkötter}
\institute{RWTH Aachen, Lehrstuhl 7 f\"ur Informatik}
\date{\today}

\maketitle





\begin{abstract}
	Exact minimization of $\omega$-automata is a difficult problem and heuristic algorithms are a subject of current research. We establish a framework to generalize the known notion of quotient automata and uniformly describe such algorithms. We investigate several approaches to reduce the state space of deterministic parity automata. These are based on extracting information from structures within the automaton, such as strongly connected components, coloring of the states, and equivalence classes of given relations, to determine states that can safely be merged. The description of these procedures consists of a theoretical analysis as well as data collected from experiments. 
	\keywords{foo \and bar}
\end{abstract}


\section{Introduction}

Finite automata are a long established computation model that dates back to sources such as \cite{McCulloch1990} and \cite{RabinScott1959}. A known problem for finite automata is state space reduction, referring to the search of a language-equivalent automaton which uses fewer states than the original object. For deterministic finite automata (DFA), not just reduction but minimization was solved in \cite{Hopcroft1971}. Regarding nondeterministic finite automata (NFA), \cite{JianRavikumar1991} proved the PSPACE-completeness of the minimization problem, which is why reduction algorithms such as \cite{ChamparnaudCoulon2004} and \cite{BonchiPous2013} are a popular alternative.

In his prominent work \cite{Buchi1966}, B\"uchi introduced the model of B\"uchi automata (BA) as an extension of finite automata to read words of one-sided infinite length. As these $\omega$-automata tend to have higher levels of complexity in comparison to standard finite automata, the potential gain of state space reduction is even greater. Similar to NFAs, exact minimization for deterministic B\"uchi automata was shown to be NP-complete in \cite{Schewe2010} and spawned heuristic approaches such as \cite{Schewe2010}, \cite{MayrClemente2012}, or \cite{EtessamiWilkeSchuller2001}. 

As \cite{Thomas1991} displays, deterministic B\"uchi automata are a strictly weaker model than nondeterministic Büchi automata. It is therefore interesting to consider different models of $\omega$-automata in which determinism is possible while maintaining enough power to describe all $\omega$-regular languages. 
Parity automata (PA) are one such model, a combination of B\"uchi automata and Moore automata (\cite{Moore56}), that use a parity function, assigning a number (called priority or color) to each state. The convention used in this paper is that even priorities correspond to \enquote{good} states while odd priorities correspond to \enquote{bad} states. The smallest priority that is seen infinitely often during a run defines its acceptance; if it is even, the run will be accepting, and if it is odd, the run will be rejecting.
\cite{Mostowski1991}, \cite{Thomas1997} showed that deterministic parity automata are indeed sufficient to recognize all $\omega$-regular languages. As for DBAs, the exact minimization problem for DPAs is NP-complete (\cite{Schewe2010}).
\vspace{5pt}

In this thesis, we investigate multiple techniques of heuristic state space reduction for DPAs. We present a general framework to uniformly describe these algorithms in a transparent manner. As opposed to a black box which provides as output a reduced automaton for each input, the framework aims towards giving more precise information about how the reduced DPA comes to be. This in theory makes it easier to find structures in the DPAs which are responsible for the reduction being applicable.
The base of the framework was the notion of quotient automata, which, for a given congruence relation on the states, merges all states of each equivalence class into one single representative. For example, building the quotient automaton of a DFA with the relation defined by the Myhill-Nerode theorem \cite{} will yield the minimal DFA for that language.

Our proposal for this framework are merger functions which generalize quotient automata. Merger functions map sets of states in the original DPA, called the merge set, to other sets of states, called the candidate set. The easiest interpretation, which we refer to as representative merge, allows us to merge all states from the merge set into any single representative that is chosen from the candidate set.

%TODO

The most basic merge simply adapts the algorithm from \cite{Hopcroft1971}. Every parity automaton can be interpreted as a Moore automaton which can then be minimized using said algorithm. In this context, we call the equivalence relation which considers two states to be equivalent if they are merged by this algorithm the \emph{Moore equivalence}. That relation is used or modified at several later points in the thesis.

A simple merger function that is introduced is the \emph{skip merger} which takes an equivalence relation that implies language equivalence on the states as a parameter and from that builds a merger function. The idea of using one given equivalence relation on the states and refining it is used several times in the thesis. This merge decides on one particular strongly connected component (SCC) of the automaton and removes all states of an equivalence class that do not lie in this SCC, essentially \enquote{skipping} all other SCCs.

We adapt the works of \cite{FritzWilke06}, who worked on alternating automata, to our case of deterministic parity automata and find that there are sufficient differences to warrant a separate analysis. The \emph{delayed simulation merger} considers two states to be equal, if on every run from those states on a shared word, if one run visits a priority at some position, the other run must visit a priority at most as high at some point in the future. It then holds that both runs will see the same smallest priority infinitely often and therefore either both accept or both reject. It suffices to choose one representative of each such equivalence class that has minimal priority and build the quotient automaton with those representatives.

The \emph{iterated Moore} merge uses the idea that on $\omega$-automata, states which are only visited finitely often are irrelevant to the acceptance of a state. In particular, trivial SCCs, i.e. states with no path back to itself, can have their priority freely changed without affecting the language of the automaton. The idea of this merger therefore is to loosen the constraints on those states and then build the usual Moore equivalence.

We bring up merging via \emph{path refinement}, which uses an existing equivalence class of some congruence relation and refines it to a point where states can safely be merged. This refinement occurs so that two states from the class are equivalent if on each path from that state back to the class, both states visit the same minimal priority. 

Another merger function is called \emph{threshold Moore}, which again refines an existing relation. Two states are considered to be equivalent under the refinement if a relaxation of Moore equivalence, that considers all priorities greater than some $k$ to be equal, matches them. In this case we require the two states to have equal priority and choose $k$ to be that exact value.

A similar but slightly different approach is the \emph{LSF} merger function. It removes the need for two states to have equal priority and instead takes the value $k$ as a parameter. On the other side it adds a requirement similar to that of the skip merger, in that the candidates of the merge are those that all lie in one single SCC if we modify the automaton to only contain those states of priority at least $k$.
\vspace{5pt}

The thesis is structured as follows: In the first chapter, we define basics notations and conventions and present some data of our empirical testing environment used to collect practical data of each approach.
In the second chapter, we establish some theoretical ground work that will be used by the rest of the thesis.
After that, we present the algorithms for state space reduction, split into one chapter for each such procedure. Each such chapter is made up of at least three sections. The first section describes the idea and definition of the algorithm and proofs well behaving properties. The second section covers how to actually compute the reduction and provides a short run time analysis. The third section shows practical data to analyze \enquote{real world} usefulness. Potential other sections contain variants or extensions of the original procedure as well as potential open questions. 
At the very end, the appendix includes small examples to show how the individual merger functions are computed and work.






